from pyspark.sql import SparkSession

# create SparkSession
spark = SparkSession.builder.appName("Spark XML Example").getOrCreate()

# read CSV file
df = spark.read.csv("dbfs:/FileStore/annual.csv")

# repartition the dataFrame into a single partition and save as a single xml file with gzip compression
# add option to disable creation of _SUCCESS file
df.repartition(1).write.format("xml") \
  .option("compression", "gzip") \
  .option("mapreduce.fileoutputcommitter.marksuccessfuljobs", "false") \
  .save("gs://bkt-d-use1-lcef-target/xml_output_hello.xml.gz")

# stop SparkSession
spark.stop()

---------------------------------------------------------------------------------


from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("Spark XML Example").getOrCreate()

spark.conf.set("mapreduce.fileoutputcommitter.marksuccessfuljobs", "false")

df = spark.read.csv("dbfs:/FileStore/annual.csv")

# repartitioning the dataFrame into a single partition and save as a single xml file with gzip compression
df.repartition(1).write.format("xml") \
  .option("compression", "gzip") \
  .save("gs://bkt-d-use1-lcef-target/xml_output_hello.xml.gz")

dbutils.fs.rm("gs://bkt-d-use1-lcef-target/xml_output_hello.xml.gz/_SUCCESS")

spark.stop()

